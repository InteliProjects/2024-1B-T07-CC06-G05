{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização inicial\n",
    "\n",
    "Foram fornecidos dois arquivos CSV de dados, um nomeado \"amostra_total.csv\" e outro \"amostra_menor.csv\". Será visualizado inicialmente o conteúdo de cada um (devem estar na mesma pasta que este arquivo para a execução)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização dos dataframes (leitura dos csv's)\n",
    "total_sample = pd.read_csv(\"./amostra_total.csv\", sep=\";\")\n",
    "smaller_sample = pd.read_csv(\"./amostra_menor.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização das primeiras 5 linhas do arquivo \"amostra_total.csv\"\n",
    "total_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização das primeiras 5 linhas do arquivo \"amostra_menor.csv\"\n",
    "smaller_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados recebidos\n",
    "\n",
    "Como observado na visualização inicial acima, supõe-se que foram recebidos dados referentes a:\n",
    "\n",
    "- Logradouros do Rio de Janeiro (colunas \"LOGRADOURO\" e \"NUMERO\");\n",
    "- Rotas de leiturização às quais os logradouros pertencem (coluna \"CODIGO_ROTA\");\n",
    "- Ordem ou índice do logradouro em determinada rota (coluna \"SEQUENCIA\");\n",
    "- Identificador único de cada logradouro em uma rota (coluna \"INDICE\");\n",
    "- Coordenadas geográficas dos logradouros (colunas \"LATITUDE\" e \"LONGITUDE\").\n",
    "\n",
    "De imediato, é necessário estudar se há dados contidos na amostra menor que não estão presentes na amostra total, se existe algum identificador repetido na coluna \"INDICE\", procurar e tratar dados nulos e realizar a conversão de tipos nas colunas \"INDICE\", \"SEQUENCIA\" e \"NUMERO\", de float/object (string) para integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação entre a amostra total e a menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação de tamanhos das amostras de dados\n",
    "total_rows         = int(total_sample.count().max())\n",
    "total_rows_smaller = int(smaller_sample.count().max())\n",
    "\n",
    "print(f\"A amostra total contém {total_rows} linhas, enquanto a amostra menor contém {total_rows_smaller}.\")\n",
    "print(f\"Dessa forma, há uma diferença de {total_rows - total_rows_smaller} linhas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste para avaliar se a amostra menor está contida na total ou se são outros dados\n",
    "df_test             = pd.merge(total_sample, smaller_sample, \"left\", \"INDICE\")\n",
    "total_plus_added  = int(df_test.count().max())\n",
    "\n",
    "if total_plus_added - total_rows == 0:\n",
    "    print(\"Todos os dados da amostra menor estão contidos na amostra total, dado que o merge entre os dois datasets não resultou em nenhuma linha adicional.\")\n",
    "else:\n",
    "    print(f\"Nem todos os dados da amostra menor estão contidos na amostra total, dado que o merge entre os dois datasets resultou em {total_plus_added - total_rows} linha(s) adicional(is).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dado que todas as informações da amostra menor estão presentes na amostra total, ela não será considerada nas análises futuras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presença de identificadores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procura por identificadores publicados\n",
    "duplicated_identifiers_mask = total_sample[\"INDICE\"].duplicated() == True\n",
    "if duplicated_identifiers_mask.any():\n",
    "    print(f\"Há {total_sample[duplicated_identifiers_mask].count().max()} identificadores duplicados nos dados.\")\n",
    "else:\n",
    "    print(\"Não há identificadores duplicados nos dados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checagem por dados nulos\n",
    "null_mask       = total_sample.isnull().any(axis=1)\n",
    "null_rows       = total_sample[null_mask].count().max()\n",
    "\n",
    "print(f\"Há {null_rows} linhas com dados nulos na amostra total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização dos dados nulos\n",
    "total_sample[null_mask].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ao que tudo indica, os dados nulos se referem a logradouros sem número registrado. Essa hipótese é verificada abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização de registros nulos em cada coluna\n",
    "for col, null_count in total_sample[null_mask].count().items():\n",
    "    if null_rows == null_count:\n",
    "        print(f'A coluna \"{col}\" não contém registros nulos.')\n",
    "    else:\n",
    "        print(f'A coluna \"{col}\" possui {null_rows - null_count} registros nulos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como a coluna \"NUMERO\" é a única com dados nulos, ou seja, mesmo sem número ainda se tem todos os outros dados relativos aquela rota e aquele logradouro, por ora os valores nulos serão substituídos por 0. Afinal, essa ação é necessária também para a conversão de tipos mencionada anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trocando valores nulos por 0\n",
    "total_sample.fillna(0, inplace=True)\n",
    "\n",
    "# Reavaliando a máscara para filtrar o dataframe por dados nulos\n",
    "null_mask = total_sample.isnull().any(axis=1)\n",
    "\n",
    "if int(total_sample[null_mask].count().max()) > 0:\n",
    "    print(\"Mesmo após substituição, o dataset ainda contém dados nulos.\")\n",
    "else:\n",
    "    print(\"Todos os valores nulos foram substituídos com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversão de tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checagem do tipo da coluna \"NUMERO\" da amostra, pois não aparentava ser float na visualização inicial (pelo menos não na amostra total)\n",
    "print(total_sample[\"NUMERO\"].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visto que o tipo da coluna \"NUMERO\" é object (string), provavelmente há registros fora do padrão que contêm letras. Esses registros são tratados abaixo.\n",
    "\n",
    "Alguns números foram registrados com complementos, então será criada uma coluna de complemento para armazenar esses dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambas as funções retornam strings pois os dados da coluna na qual serão aplicadas estão neste formato\n",
    "def get_adress_number_and_complement(s : pd.Series) -> list[str, str]:\n",
    "    \"\"\"\n",
    "    Recebe um registro do dataset das colunas \"NUMERO\" e \"COMPLEMENTO\" e retorna o número\n",
    "    devidamente processado (ou seja, com letras e caracteres não-numéricos retirados) e o\n",
    "    complemento do endereço caso esteja contido na coluna \"NUMERO\". Caso contrário, o\n",
    "    complemento é retorado como \"N\" (de \"Não\").\n",
    "\n",
    "    Parâmetros:\n",
    "    - s: pd.Series / registro das colunas \"NUMERO\" e \"COMPLEMENTO\".\n",
    "\n",
    "    Retorno:\n",
    "    - [número sem caracteres não-numéricos, complemento].\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return [str(int(s[\"NUMERO\"])), \"N\"]\n",
    "    except:\n",
    "        return get_number_and_complement_within_str(s[\"NUMERO\"].strip())\n",
    "\n",
    "\n",
    "def get_number_and_complement_within_str(s : str) -> list[str, str]:\n",
    "    \"\"\"\n",
    "    Recebe uma string e tenta retornar um número nela contido\n",
    "    e o restante da string como complemento. Caso não encontre um\n",
    "    número, retorna [\"0\", restante da string]. Caso não haja uma\n",
    "    parte restante da string, essa é substituída no retorno por \"N\"\n",
    "    (de \"Não\").\n",
    "\n",
    "    Parâmetros:\n",
    "    - s: string que supostamente contém um número.\n",
    "\n",
    "    Retorno:\n",
    "    - [número contido na string enviada como parâmetro, restante da string].\n",
    "    \"\"\"\n",
    "    found = False\n",
    "    number = \"\"\n",
    "    initial_index = 0\n",
    "    for i in range(len(s)):\n",
    "        try:\n",
    "            number += str(int(s[i]))\n",
    "            if not found:\n",
    "                initial_index = i                \n",
    "            found = True\n",
    "        except:\n",
    "            if found:\n",
    "                return [number, s[0:initial_index] + s[i:]]\n",
    "            continue\n",
    "    \n",
    "    return [number, s[0:initial_index]] if number != \"\" else [\"0\", \"N\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento das strings na coluna \"NUMERO\"\n",
    "total_sample[\"COMPLEMENTO\"] = \"\"\n",
    "total_sample[[\"NUMERO\", \"COMPLEMENTO\"]] = total_sample[[\"NUMERO\", \"COMPLEMENTO\"]].apply(get_adress_number_and_complement, axis=1, result_type=\"broadcast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão de float para integer\n",
    "total_sample[\"INDICE\"]     = total_sample[\"INDICE\"].astype(int)\n",
    "total_sample[\"SEQUENCIA\"]  = total_sample[\"SEQUENCIA\"].astype(int)\n",
    "total_sample[\"NUMERO\"]     = total_sample[\"NUMERO\"].astype(int)\n",
    "\n",
    "for col in total_sample.columns:\n",
    "    print(f'Tipo da coluna \"{col}\": {total_sample[col].dtype}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização dos dados com tipos convertidos\n",
    "total_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordenação dos dados\n",
    "\n",
    "A partir desse tratamento inicial, ordena-se os dados de acordo com as colunas \"CODIGO_ROTA\" e \"SEQUENCIA\", a fim de organizar as informações, visualizar o trajeto de cada rota de forma ordenada e possivelmente gerar insights para próximos passos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenação dos dados de acordo com as colunas mencionadas\n",
    "total_sample = total_sample.sort_values(by=[\"CODIGO_ROTA\", \"SEQUENCIA\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização dos dados ordenados\n",
    "total_sample.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registros duplicados\n",
    "\n",
    "Apesar dos identificadores únicos não apresentarem duplicatas, observa-se após a ordenação registros que indicam a existência de duplicatas nos dados, dado que o código da rota, o logradouro e o número do endereço são idênticos em mais de uma linha. O mais alarmante é que existem registros em que, além dos dados mencionados, o número de sequência também é igual, o que indica uma possível reinserção de dados idênticos.\n",
    "\n",
    "Essa hipótese é verificada a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação da existência de registros supostamente duplicados\n",
    "duplicated_mask = total_sample[[\"CODIGO_ROTA\", \"LOGRADOURO\", \"NUMERO\"]].duplicated(keep=\"last\") == True\n",
    "duplicated_rows = int(total_sample[duplicated_mask].count().max())\n",
    "total_rows      = int(total_sample.count().max())\n",
    "percentage = \"%.2f\" % (duplicated_rows / total_rows * 100)\n",
    "\n",
    "if duplicated_rows > 0:\n",
    "    print(f\"Há {duplicated_rows} registros duplicados nos dados. Ou seja, {percentage}% dos dados ({duplicated_rows} registros duplicados para {total_rows} registros totais).\")\n",
    "else:\n",
    "    print(\"Não há registros duplicados nos dados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hipótese: dados duplicados se referem a registros de hidrômetros localizados em um mesmo logradouro, fenômeno observado em sobrados e prédios por exemplo\n",
    "\n",
    "Dessa forma, será criada uma coluna que registra a quantidade de hidrômetros em cada logradouro. Antes, porém, é necessário avaliar se as distâncias registradas nas colunas \"LATITUDE\" e \"LONGITUDE\" são significativas, o que poderia negar a hipótese acima. Esse processo é realizado a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação do desvio padrão da latitude e longitude dos dados repetidos\n",
    "coordinates_std = total_sample.groupby([\"CODIGO_ROTA\", \"LOGRADOURO\", \"NUMERO\"])[[\"LATITUDE\", \"LONGITUDE\"]].std().reset_index()\n",
    "all_rows = int(coordinates_std.count().max())\n",
    "\n",
    "std_greater_than_zero = (coordinates_std[[\"LATITUDE\", \"LONGITUDE\"]] > 0).any(axis=1)\n",
    "gt_zero_rows = int(coordinates_std[std_greater_than_zero].count().max())\n",
    "\n",
    "coordinates_std[std_greater_than_zero][[\"LATITUDE\", \"LONGITUDE\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação do desvio padrão da latitude e longitude dos dados totais\n",
    "coordinates_std[[\"LATITUDE\", \"LONGITUDE\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observa-se que pelo menos 75% dos dados duplicados que apresentam um desvio padrão maior que 0 nas medidas de coordenadas geográficas (latitude e longitude) não ultrapassam o limite de 0.00007 nesse desvio padrão, o que representa uma diferença insignificante e corrobora a hipótese apresentada.\n",
    "\n",
    "Essa afirmação é reforçada pelo fato de que, ao analisar-se o desvio padrão para essas medidas com os dados totais (não só os duplicados), pelo menos 75% não ultrapassa o limite de 0.000055 no desvio padrão.\n",
    "\n",
    "Entretanto, ainda há um volume desses dados duplicados (25% no máximo) que apresenta um desvio padrão significativo (considerou-se maior que 0.0001 como significativo) e que deve ser verificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação do volume de dados com desvio padrão significativo\n",
    "coordinates_std_mask = (coordinates_std[[\"LATITUDE\", \"LONGITUDE\"]] > 0.0001).any(axis=1)\n",
    "relevant_rows = int(coordinates_std[coordinates_std_mask].count().max())\n",
    "percentage = \"%.2f\" % (relevant_rows / gt_zero_rows * 100)\n",
    "\n",
    "print(f\"\"\"Dos dados duplicados que apresentam um desvio padrão maior que 0 nas medidas de coordenadas geográficas (latitude e longitude),\n",
    "{percentage}% tem valor significativo de desvio padrão ({relevant_rows} registros significativos para {gt_zero_rows} registros analisados).\n",
    "\n",
    "Em comparação com os dados totais (agrupadas as duplicatas), esses registros significativos representam {\"%.2f\" % (relevant_rows / all_rows * 100)}%\n",
    "({relevant_rows} registros significativos para {all_rows} registros totais).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dado o baixo volume de registros com desvio padrão relevante, por ora, será considerado que a diferença observada entre os registros de coordenadas geográficas para dados duplicados é irrelevante, possibilitando a criação da coluna de quantidade de hidrômetros e o descarte dos dados duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a coluna de quantidade de hidrômetros\n",
    "hydrometer_amount = total_sample.groupby([\"CODIGO_ROTA\", \"LOGRADOURO\", \"NUMERO\"]).size().reset_index().rename(columns={0: \"QUANTIDADE_HIDROMETROS\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pressupondo que os dados duplicados são dispensáveis, uma vez que se tem as quantidades de hidrômetros para cada logradouro, os mesmos são descartados a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descartando dados duplicados e adicionando a coluna de quantidade de hidrômetros\n",
    "sample_with_quantity = total_sample.drop(total_sample[duplicated_mask].index).merge(hydrometer_amount, \"inner\", [\"CODIGO_ROTA\", \"LOGRADOURO\", \"NUMERO\"])\n",
    "sample_with_quantity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento da coluna \"SEQUENCIA\"\n",
    "\n",
    "Observa-se que a coluna \"SEQUENCIA\" possui registros inconsistentes. Por exemplo, a rota \"10_14\" só possui um registro nos dados recebidos, porém seu número de sequência é 2160, o que indica que deveriam haver outros 2159 registros para essa rota, já que a sequência indica o índice daquele logradouro dentro daquela rota (ou seja, a ordem de leiturização).\n",
    "\n",
    "Além disso, há rotas com diferentes endereços possuindo o mesmo número de sequência.\n",
    "\n",
    "Por fim, com a limpeza de dados duplicados, algumas sequências apresentam saltos em algumas rotas, e não uma ordem de crescimento linear, o que também precisa ser corrigido.\n",
    "\n",
    "Dessa forma, o número de sequência dos registros será recomputado para cada rota, a fim de torná-lo coerente com os registros presentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando valores de sequência que não começam em 0 como o caso da rota \"10_14\", valores duplicados de sequência e saltos na sequência\n",
    "routes = sample_with_quantity.groupby(\"CODIGO_ROTA\")\n",
    "sample_with_quantity[\"SEQUENCIA\"] = routes.cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se ainda existem valores incoerentes\n",
    "if sample_with_quantity[[\"CODIGO_ROTA\", \"SEQUENCIA\"]].duplicated().any():\n",
    "    print(\"Ainda há valores duplicados de sequência.\")\n",
    "else:\n",
    "    print(\"Todos os valores duplicados de sequência foram eliminados.\")\n",
    "\n",
    "sample_with_quantity.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalização da análise e do tratamento\n",
    "\n",
    "Com todas as etapas de tratamento realizadas acima, possibilitadas pela análise feita, conclui-se o o processo de análise e tratamento inicial dos dados, objetivo deste Jupyter Notebook. Por fim, os dados tratados são exportados para o caminho \"./dados_tratados/dados_tratados.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./dados_tratados/\"):\n",
    "    os.mkdir(\"./dados_tratados/\")\n",
    "\n",
    "sample_with_quantity.to_csv(\"./dados_tratados/dados_tratados.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informações fornecidas pelo parceiro após reunião\n",
    "\n",
    "Após reunião de alinhamento acerca do projeto, os parceiros de negócios ratificaram todas as hipóteses supramencionadas e apontaram que o tratamento realizado nos dados está, em sua maioria, correto. O único ponto de ajuste seria o descarte dos dados duplicados, que não pode ser feito de forma irreversível, pois as informações únicas de cada rota (ou seja, seu identificador único) devem estar presentes em um possível output. Ou seja, esse descarte será feito de forma temporária apenas para a etapa de processamento e utilização dos dados pelo backend do projeto, provendo uma execução otimizada dos algoritmos, e será retornado ao frontend uma versão expandida do output do backend, incluindo dados previamente descartados.\n",
    "\n",
    "Dessa forma, como próxima etapa de trabalho com os dados recebidos, será estruturada uma pipeline de tratamento padronizada e generalizada, para que assim a aplicação desenvolvida possa receber diferentes inputs de dados no formato CSV (conservando, claro, a estrutura de dados existente) e gerar outputs diferenciados para cada amostra.\n",
    "\n",
    "Além disso, segundo o parceiro, serão enviados novos dados idênticos aos já recebidos, porém contendo também o complemento dos endereços como uma nova coluna do dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recebimento de novos dados: coordenadas geográficas das bases\n",
    "\n",
    "Foram recebidas informações a respeito das coordenadas geográficas (latitude e longitude) das duas bases da Aegea Saneamento na cidade do Rio de Janeiro, ou seja, os locais que representam o início do percurso de todos os leituristas, pois é de onde saem para realizar seu trabalho.\n",
    "Esses dados serão mostrados abaixo, mas é necessário mencionar que eles não serão incluídos na etapa inicial do desenvolvimento do projeto por conta do aumento do escopo que acompanha essa mudança."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo as coordenadas geográficas das bases (passadas por um arquivo TXT que deve estar na mesma pasta que este arquivo para a execução)\n",
    "bases = open(\"bases.txt\")\n",
    "\n",
    "print(\"Coordenadas geográficas das bases\\n\" + bases.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
