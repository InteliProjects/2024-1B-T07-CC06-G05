{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6-LFy-ksVLQ"
      },
      "source": [
        "# Importações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOYnWlvvsVLS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8_vhHynBvOG"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"./dados_tratados.csv\",sep=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "G2EhWojjB83X",
        "outputId": "003d70b4-80ad-4b35-ea22-c8db2e03cd52"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8hcM0G1smvb"
      },
      "source": [
        "# Clusterização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ganTYpD8sq3T"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR6xiY4PLijN"
      },
      "source": [
        "Calculo para o numero de clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huoqda_SexVK",
        "outputId": "1ef9133b-e912-4b92-84ac-94bc0a9bb9b7"
      },
      "outputs": [],
      "source": [
        "data.shape[0]/(400*22)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMZYSPOasqyE"
      },
      "outputs": [],
      "source": [
        "X=data.iloc[:,1:3].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9lhpalELyS0"
      },
      "source": [
        "Instacia do objeto kmeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DILaGj04LoXa"
      },
      "outputs": [],
      "source": [
        "n_dia = 400\n",
        "dias =22\n",
        "kmeans = KMeans(n_clusters=int(data.shape[0]/(n_dia*dias)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJlCEkRpL_bi"
      },
      "source": [
        "Treinamento com os dados de longitude e latitude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kmeans.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "DknlmRHVsqva",
        "outputId": "185f594d-3dea-46bd-a6e3-15f2955011ea"
      },
      "outputs": [],
      "source": [
        "kmeans.fit(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFWr6BBfMDpK"
      },
      "source": [
        "Atribuição dos clusters aos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pZJcgBCxFz5"
      },
      "outputs": [],
      "source": [
        "pred =kmeans.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XceRy_A5MHi-"
      },
      "source": [
        "Criação dos clusters de leituristas no dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUPqlGQGGAwJ"
      },
      "outputs": [],
      "source": [
        "data[\"cluster_leiturista\"] = pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUbEAJzBMMKk"
      },
      "source": [
        "Criação dos clusters de dias para cada leiturista/cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEf3HWYUsqnt",
        "outputId": "9547318d-4f7c-4b4b-df14-da6d7c2a02b8"
      },
      "outputs": [],
      "source": [
        "dias_leitura = 22\n",
        "data['cluster_dia'] = 0\n",
        "for i in np.unique(kmeans.labels_):\n",
        "  X = data.loc[data[\"cluster_leiturista\"]==i].iloc[:,1:3].values\n",
        "  kmeans2 = KMeans(n_clusters=dias_leitura)\n",
        "  pred2=kmeans2.fit_predict(X)\n",
        "  data.loc[data[\"cluster_leiturista\"]==i,'cluster_dia']=pred2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def balancing_kmeans_day(data:pd.DataFrame, centroids_coords,ponts_qtd):\n",
        "    conflicts = []\n",
        "    grouped=data.groupby('cluster_leiturista')\n",
        "    \n",
        "    conflicts_qtd =0\n",
        "    qtd_clusters=0\n",
        "    \n",
        "    for _, group in grouped:\n",
        "    \n",
        "        clusters = group.groupby('cluster_dia')\n",
        "        solution_leiturista = []\n",
        "        solution_distance = 0\n",
        "\n",
        "\n",
        "        for label, cluster in clusters:\n",
        "            qtd_clusters+=1\n",
        "            qtd_points = cluster.shape[0]\n",
        "            if qtd_points<(ponts_qtd - 0.05*ponts_qtd) or qtd_points>(ponts_qtd + 0.5*ponts_qtd):\n",
        "                conflicts.append(cluster)\n",
        "                conflicts_qtd+=1\n",
        "    print(conflicts_qtd)\n",
        "    print(qtd_clusters)\n",
        "\n",
        "            \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, j in enumerate(kmeans.cluster_centers_):\n",
        "    print(i)\n",
        "    print(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from haversine import haversine, Unit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def verify_excess(data,days,ponts_qtd):\n",
        "    grouped=data.groupby('cluster_leiturista')\n",
        "\n",
        "    for _, group in grouped:\n",
        "        qtd_points = group.shape[0]\n",
        "        if qtd_points/days > (ponts_qtd +50):\n",
        "            if qtd_points/days - ponts_qtd >0.5*ponts_qtd:\n",
        "                return True\n",
        "    return False\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def balancing_kmeans_leit(data:pd.DataFrame, centroids_coords,ponts_qtd,days):\n",
        "    grouped=data.groupby('cluster_leiturista')\n",
        "    excess =0\n",
        "    lack =0\n",
        "    lack_list = []\n",
        "    excess_list = []\n",
        "    excess_index =[]\n",
        "    conflicts_qtd =0\n",
        "    qtd_clusters=0\n",
        "    excess_gap=0\n",
        "    lack_gap = 0\n",
        "    lack_index=[]\n",
        "    clusters_proximity = []\n",
        "    trocas = []\n",
        "    for _, group in grouped:\n",
        "    \n",
        "        clusters = group.groupby('cluster_dia')\n",
        "        solution_leiturista = []\n",
        "        add_cl=0\n",
        "        solution_distance = 0\n",
        "        qtd_clusters+=1\n",
        "        qtd_points = group.shape[0]\n",
        "        if qtd_points/days < (ponts_qtd-10) :\n",
        "            lack+=1\n",
        "            lack_list.append({\"cluster\":group['cluster_leiturista'].values[0],\"lack_per_day\":abs(qtd_points/days - ponts_qtd) ,\"points_quantity\":qtd_points/22})\n",
        "            lack_index.append(group['cluster_leiturista'].values[0])\n",
        "            lack_gap += abs(qtd_points/days - ponts_qtd)\n",
        "            if abs(qtd_points/days - ponts_qtd) >ponts_qtd:\n",
        "                lack_list.append(group['cluster_leiturista'].values[0])\n",
        "                print(f'ponts_gaps:{qtd_points/days - ponts_qtd}')\n",
        "                print(f'pointsqtd: {qtd_points/days}')\n",
        "        if qtd_points/days > (ponts_qtd +50):\n",
        "            if qtd_points/days - ponts_qtd >0.5*ponts_qtd:\n",
        "                print(qtd_points)\n",
        "                excess+=1\n",
        "                excess_list.append({\"cluster\":group['cluster_leiturista'].values[0],\"excess_per_day\":qtd_points/days - ponts_qtd ,\"points_quantity\":qtd_points/22})\n",
        "                excess_index.append(group['cluster_leiturista'].values[0])\n",
        "\n",
        "                kmeans3 =KMeans(n_clusters=2)\n",
        "                clusters_index = group[\"cluster_leiturista\"].values[0]\n",
        "                group_data = data.loc[data[\"cluster_leiturista\"]==clusters_index].iloc[:,2:4].values\n",
        "                print(clusters_index)\n",
        "                print(data[\"cluster_leiturista\"].unique())\n",
        "                group_coords =group.iloc[:,2:4].values\n",
        "                print(group_coords)\n",
        "                kmeans3.fit(group_coords)\n",
        "                pred = kmeans3.predict(group_data)\n",
        "                pred = pred+100 + int(10*random.random())\n",
        "                print(np.unique(pred,return_counts=True))\n",
        "                print(pred)\n",
        "                data.loc[data[\"cluster_leiturista\"]==clusters_index,'cluster_leiturista'] = pred\n",
        "                for i in np.unique(pred):\n",
        "                    X = data.loc[data[\"cluster_leiturista\"]==i].iloc[:,2:4].values\n",
        "                    kmeans4 = KMeans(n_clusters=days)\n",
        "                    pred2=kmeans4.fit_predict(X)\n",
        "                    data.loc[data[\"cluster_leiturista\"]==i,'cluster_dia']=pred2\n",
        "\n",
        "                print(f'ponts_gaps:{qtd_points/days - ponts_qtd}')\n",
        "                print(f'pointsqtd: {qtd_points/days}')\n",
        "                excess_list.remove(excess_list[-1])\n",
        "                excess_index.remove(excess_index[-1])\n",
        "                \n",
        "            excess_gap += abs(qtd_points/days - ponts_qtd)\n",
        "\n",
        "    for cluster, coords in enumerate(kmeans.cluster_centers_):\n",
        "        coords_distances = []\n",
        "        for cluster2, coords2 in enumerate(kmeans.cluster_centers_):\n",
        "            if cluster != cluster2:\n",
        "                dist = haversine(coords, coords2, unit=Unit.KILOMETERS)\n",
        "                coords_distances.append({\"cluster_\":cluster2,\"distance\":dist})\n",
        "        coords_distances.sort(key=lambda x: x[\"distance\"])\n",
        "        clusters_proximity.append({\"cluster_origin\":cluster,\"clusters_proximities\":coords_distances})\n",
        "    clusters_proximity.sort(key= lambda x:x[\"cluster_origin\"])\n",
        "\n",
        "    for i in excess_list:\n",
        "        proximites = clusters_proximity[i[\"cluster\"]]\n",
        "        for j in proximites[\"clusters_proximities\"]:\n",
        "            if j[\"cluster_\"] in lack_index:\n",
        "                lack = lack_index.index(j[\"cluster_\"])\n",
        "                print(f'distance between {proximites[\"cluster_origin\"]},{j[\"cluster_\"]} : {j[\"distance\"]}  ')\n",
        "                print(f'excess: {i[\"excess_per_day\"]}')\n",
        "\n",
        "                print(f'lack: {lack_list[lack][\"lack_per_day\"]}')\n",
        "                break\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    print(f'excess_qtd:{excess}')\n",
        "    print(f'lack_qtd:{lack}')\n",
        "    print(f'excess_gap:{excess_gap}')\n",
        "    print(f'excess_gap_in_leit:{excess_gap/days}')\n",
        "    print(f'lack_list:{lack_list}')\n",
        "    print(f'excess_list:{excess_list}')\n",
        "    print(f'lack_gap:{lack_gap}')\n",
        "    print(clusters_proximity)\n",
        "    print(clusters_proximity[4])\n",
        "    \n",
        "\n",
        "            \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "balancing_kmeans_leit(data,0,400,22)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt = data.loc[(data[\"cluster_leiturista\"]== 100 )|(data[\"cluster_leiturista\"]== 101 )] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt.shape[0]/22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv('dados_tratados_clusterizados_400.csv')\n",
        "balancing_kmeans_leit(data,0,400,22)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data[\"cluster_leiturista\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "BqpD7RMo2ABc",
        "outputId": "da86d410-e227-4675-c15e-fd81145ab555"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x=dt['LONGITUDE'],y=dt['LATITUDE'],hue = dt['cluster_leiturista'], palette=sns.color_palette(\"Spectral\", as_cmap=True))\n",
        "sns.scatterplot(x=clis[:,1],y=clis[:,0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "14837/22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.loc[data[\"cluster_leiturista\"]==103].shape[0]/22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data[\"cluster_leiturista\"].unique().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "balancing_kmeans_leit(data,0,200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCEoGbNMMYML"
      },
      "source": [
        "verificaçãodo dataframe novo para o cluster de leiturista 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "O82CfQc9HOc1",
        "outputId": "9478ec4d-92ca-4b60-c2f9-95d5f2fa6512"
      },
      "outputs": [],
      "source": [
        "data.loc[data[\"cluster_leiturista\"]==1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4hjJrlKv2uj"
      },
      "outputs": [],
      "source": [
        "clis = kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW1ioCeLv7N9"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ltdYEeEMeya"
      },
      "source": [
        "Plot dos clusters de leituristas para todos os dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt0gaqYux0Fx"
      },
      "outputs": [],
      "source": [
        "dia_ex = data.loc[data[\"cluster_leiturista\"]==10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbIZL7eDMjep"
      },
      "source": [
        "plot dos clusters de dias do leiturista de numero 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "0CRSwQGsJzrJ",
        "outputId": "734ba749-dd06-41da-8e10-9adf689d7d65"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(data = dia_ex,x=\"LONGITUDE\",y=\"LATITUDE\",hue=\"cluster_dia\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkLTta9Picy0"
      },
      "outputs": [],
      "source": [
        "data.to_csv(\"./dados_tratados_clusterizados_400.csv\",sep=\",\",encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from haversine import haversine, Unit\n",
        "\n",
        "grouped=data.groupby('cluster_leiturista')\n",
        "solutions =[]\n",
        "for _, group in grouped:\n",
        "   \n",
        "    clusters = group.groupby('cluster_dia')\n",
        "    solution_leiturista = []\n",
        "    solution_distance = 0\n",
        "\n",
        "    for label, cluster in clusters:\n",
        "        coords = cluster[['LATITUDE', 'LONGITUDE']].to_numpy()   \n",
        "\n",
        "\n",
        "        n = len(coords)\n",
        "        distance_matrix = np.zeros((n, n))\n",
        "        qtd_matrix = cluster['QUANTIDADE_HIDROMETROS'].values\n",
        "        qtd_matrix=np.insert(qtd_matrix,[0],[0],axis=0)\n",
        "        for i in range(n):\n",
        "            for j in range(i + 1, n):\n",
        "                distance_matrix[i, j] = distance_matrix[j, i] = haversine(coords[i], coords[j], unit=Unit.KILOMETERS)\n",
        "\n",
        "        "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
